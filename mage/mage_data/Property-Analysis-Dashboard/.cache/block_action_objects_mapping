{"block_file": {"data_exporters/export_titanic_clean.py:data_exporter:python:export titanic clean": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#example-loading-data-from-a-file\n    \"\"\"\n    filepath = 'titanic_clean.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/export_titanic_clean.py", "language": "python", "type": "data_exporter", "uuid": "export_titanic_clean"}, "data_loaders/load_titanic.py:data_loader:python:load titanic": {"content": "import io\nimport pandas as pd\nimport requests\nfrom pandas import DataFrame\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(**kwargs) -> DataFrame:\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n\n    return pd.read_csv(url)\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_titanic.py", "language": "python", "type": "data_loader", "uuid": "load_titanic"}, "transformers/fill_in_missing_values.py:transformer:python:fill in missing values": {"content": "from pandas import DataFrame\nimport math\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\ndef select_number_columns(df: DataFrame) -> DataFrame:\n    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n\n\ndef fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n    for col in df.columns:\n        values = sorted(df[col].dropna().tolist())\n        median_age = values[math.floor(len(values) / 2)]\n        df[[col]] = df[[col]].fillna(median_age)\n    return df\n\n\n@transformer\ndef transform_df(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        df (DataFrame): Data frame from parent block.\n\n    Returns:\n        DataFrame: Transformed data frame\n    \"\"\"\n    # Specify your transformation logic here\n\n    return fill_missing_values_with_median(select_number_columns(df))\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "transformers/fill_in_missing_values.py", "language": "python", "type": "transformer", "uuid": "fill_in_missing_values"}, "/home/src/Property-Analysis-Dashboard/data_loaders/project_scrap.py:data_loader:python:home/src/Property-Analysis-Dashboard/data loaders/project scrap": {"content": "import io\nimport pandas as pd\nimport requests\nfrom pandas import DataFrame\nimport csv\nimport bs4\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport re\nimport json\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(**kwargs) -> pd.DataFrame:\n\n\n    columns = [\"Current date\", \"Current time\", \"ID\", \"Added date\", \"Update date\", \"Price\", \"Area\",\n            \"Rooms\", \"floor\", \"rent\", \"form of ownership\", \"condition\",\n            \"arrangements\", \"heating\", \"market\", \"advertiser type\",\n            \"building year\", \"material1\", \"elevator\", \"material2\", \"link\"]\n    df = pd.DataFrame(columns=columns)\n\n    # Create a session object\n    session = requests.Session()\n    # Set headers to mimic a browser visit\n    session.headers.update({\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'\n    })\n\n    search_url = 'https://www.otodom.pl/pl/wyniki/sprzedaz/mieszkanie/malopolskie/krakow'\n    df = scrape_otodom(search_url, df, session)\n    return df\n    \n    \n# Main scraping function\ndef scrape_otodom(search_url, df, session):\n    max_pages = get_max_pages(search_url, session)\n    raw_links = fetch_raw_links(search_url, max_pages, session)\n    for link in raw_links:\n        df = fetch_data_from_raw_link(df, link, session)\n    return df\n    \n# Function to determine the number of pages in the search results\ndef get_max_pages(search_url, session):\n    response = session.get(search_url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    pages_count_div = soup.find(\"div\", class_=\"css-18budxx e18zekwa0\")\n    if not pages_count_div:\n        return 1  # Assume there's at least one page if no navigation is found\n    list_page_numbers = pages_count_div.find_all(\"li\", class_=\"css-1tospdx\")\n    numbers = [int(item.text) for item in list_page_numbers if item.text.isdigit()]\n    return max(numbers) if numbers else 1\n\n# Function to fetch raw links from each page\ndef fetch_raw_links(search_url, max_number, session):\n    raw_links = []\n    for i in range(1, max_number + 1):\n        page_url = f\"{search_url}?page={i}\"\n        response = session.get(page_url)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        a_tags = soup.find_all(\"a\", class_=\"css-16vl3c1 e1x0p3r10\")\n        for a_tag in a_tags:\n            if a_tag and a_tag.get(\"href\"):\n                raw_links.append(\"https://www.otodom.pl\" + a_tag.get(\"href\"))\n\n    print(f\"Total links fetched: {len(raw_links)}\")\n    raw_links = list(dict.fromkeys(raw_links))\n\n    print(f\"Total links wihout dups: {len(raw_links)}\")       \n    return raw_links\n\ndef fetch_data_from_raw_link(df, link, session):\n    response = session.get(link)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    #ad id and addition date \n    id = otodom_get_ad_id(soup)\n    addition_date = otodom_get_addition_date(soup)\n    update_date = otodom_get_update_date(soup)\n\n    #add general info\n    price = otodom_get_ad_price(soup)\n    area = otodom_get_area(soup)\n    rooms = otodom_get_rooms(soup)\n    floor = otodom_get_floor(soup)\n    rent = otodom_get_rent(soup)\n    form_of_ownership = otodom_get_form_of_ownership(soup)\n    condition = otodom_get_condition(soup)\n    arrangements = otodom_get_arrangements(soup)\n    heating = otodom_get_heating(soup)\n\n    #add additional info\n    market = otodom_get_market(soup)\n    advertiser_type = otodom_get_heating(soup)\n    building_year = otodom_get_building_year(soup)\n    material1 = otodom_get_material1(soup)\n    elevator = otodom_get_elevator(soup)\n    material2 = otodom_get_material2(soup)    \n\n    df = append_to_dataframe(df, id, addition_date, update_date, price, area, rooms,\n                floor, rent, form_of_ownership, condition,\n                    arrangements, heating, market, advertiser_type,\n                    building_year, material1, elevator, material2, link)\n    return df\n\ndef append_to_dataframe(df, id, addition_date, update_date, price, area, rooms,\n                        floor, rent, form_of_ownership, condition,\n                        arrangements, heating, market, advertiser_type,\n                        building_year, material1, elevator, material2, link):\n    \n    # Generate current timestamp\n    now = datetime.now()\n    current_date = now.strftime(\"%d/%m/%Y\")\n    current_time = now.strftime(\"%H:%M:%S\")\n\n    # Prepare the data as a dictionary\n    data = {\n        \"Current date\": current_date,\n        \"Current time\": current_time,\n        \"ID\": id,\n        \"Added date\": addition_date,\n        \"Update date\": update_date,\n        \"Price\": price,\n        \"Area\": area,\n        \"Rooms\": rooms,\n        \"floor\": floor,\n        \"rent\": rent, \n        \"form of ownership\": form_of_ownership, \n        \"condition\": condition,\n        \"arrangements\": arrangements, \n        \"heating\": heating, \n        \"market\": market, \n        \"advertiser type\": advertiser_type,\n        \"building year\": building_year, \n        \"material1\": material1, \n        \"elevator\": elevator, \n        \"material2\": material2,\n        \"link\": link\n    }\n\n    # Append the data to the DataFrame\n    df = df.append(data, ignore_index=True)\n    return df\n\n#ad id info\n\ndef otodom_get_ad_id(soup):\n    title_tag = soup.find(\"title\")\n    if title_tag:\n        title_text = title_tag.get_text(strip=True)\n        if matches := re.search(r\"(\\d+) \u2022 www\\.otodom\\.pl\", title_text):\n            return int(matches.group(1))\n    return None\n\ndef otodom_get_addition_date(soup):\n    added_date_tag = soup.find('script', id='__NEXT_DATA__')\n    if added_date_tag:\n        data = json.loads(added_date_tag.string)\n        # Access specific fields\n        created_at = data['props']['pageProps']['ad']['createdAt']\n        return created_at        \n    return None\n\ndef otodom_get_update_date(soup):\n    added_date_tag = soup.find('script', id='__NEXT_DATA__')\n    if added_date_tag:\n        data = json.loads(added_date_tag.string)\n        # Access specific fields\n        modified_at = data['props']['pageProps']['ad']['modifiedAt']\n        return modified_at   \n    return None\n\n#ad general info\ndef otodom_get_ad_price(soup):\n    try:\n        ad_price_info = soup.find(\"strong\", class_=\"css-t3wmkv e1l1avn10\")\n        ad_price_text = ad_price_info.get_text(strip=True)\n        ad_price = re.sub(r\"[^\\d.]\", \"\", ad_price_text)\n        return ad_price or '0'  # Return '0' if ad_price is empty or None\n    except Exception as e:\n        \n        return '0'  # Return a default value in case of an error\n\ndef otodom_get_area(soup):\n    try:\n        area_info = soup.find(\"div\", {\"data-testid\":\"table-value-area\"})\n        area = area_info.get_text(strip=True)\n        return area or '0'\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_rooms(soup):\n    try:\n        rooms_info = soup.find(\"div\", {\"table-value-rooms_num\"})\n        rooms = rooms_info.get_text(strip=True)\n        return rooms or '0'\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_floor(soup):\n    try:\n        floor_info = soup.find(\"div\", {\"table-value-floor\"})\n        floor = floor_info.get_text(strip=True)\n        return floor or '0'\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_rent(soup):\n    try:\n        rent_info = soup.find(\"div\", {\"data-testid\":\"table-value-rent\"})\n        rent = rent_info.get_text(strip=True)\n        return rent\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_form_of_ownership(soup):\n    try:\n        form_of_ownership_info = soup.find(\"div\", {\"data-testid\":\"table-value-building_ownership\"})\n        form_of_ownership = form_of_ownership_info.get_text(strip=True)\n        return form_of_ownership\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_condition(soup):\n    try:\n        condition_info = soup.find(\"div\", {\"data-testid\":\"table-value-construction_status\"})\n        condition = condition_info.get_text(strip=True)\n        return condition\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_arrangements(soup):\n    try:\n        arrangements_info = soup.find(\"div\", {\"data-testid\":\"table-value-outdoor\"})\n        arrangements = arrangements_info.get_text(strip=True)\n        return arrangements\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_heating(soup):\n    try:\n        heating_info = soup.find(\"div\", {\"data-testid\":\"table-value-heating\"})\n        heating = heating_info.get_text(strip=True)\n        return heating\n    except Exception as e:\n        \n        return '0'\n\n# ad additional info\n\ndef otodom_get_market(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-market\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_advertiser_type(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-advertiser_type\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_building_year(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-build_year\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_material1(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-building_type\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_elevator(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-lift\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\ndef otodom_get_material2(soup):\n    try:\n        market_info = soup.find(\"div\", {\"data-testid\": \"table-value-building_material\"})\n        market = market_info.get_text(strip=True)\n        return market\n    except Exception as e:\n        \n        return '0'\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n\n", "file_path": "/home/src/Property-Analysis-Dashboard/data_loaders/project_scrap.py", "language": "python", "type": "data_loader", "uuid": "project_scrap"}, "/home/src/Property-Analysis-Dashboard/data_exporters/write_to_bigquery.sql:data_exporter:sql:home/src/Property-Analysis-Dashboard/data exporters/write to bigquery": {"content": "-- Docs: https://docs.mage.ai/guides/sql-blocks\nSELECT * FROM {{ df_1 }}", "file_path": "/home/src/Property-Analysis-Dashboard/data_exporters/write_to_bigquery.sql", "language": "sql", "type": "data_exporter", "uuid": "write_to_bigquery"}, "/home/src/Property-Analysis-Dashboard/transformers/project_transform.py:transformer:python:home/src/Property-Analysis-Dashboard/transformers/project transform": {"content": "import pandas as pd\nfrom pandas import DataFrame\nimport math\nfrom datetime import datetime\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n# def transform_datatypes(df: DataFrame):\n#     return df\n\n@transformer\ndef transform_df(df: DataFrame, *args, **kwargs) -> DataFrame:\n    df['Area'] = df['Area'].str.replace(' m\u00b2', '')\n    df['Area'] = df['Area'].str.replace(',', '.')\n    df['Area'] = df['Area'].str.replace('\\xa0', '', regex=True)\n    df['Area'] = df['Area'].astype(float).fillna(0.0)\n\n    df = df.astype(\n        {\n            \"ID\": int,\n            \"Area\": float,\n            \"Price\": float\n            # \"Rooms\": int,\n            # \"floor\": int,\n            # \"rent\": float,\n            # \"building year\": int    \n        }\n    )\n\n    df['Price per m2'] = (df['Price'] / df['Area']).round(1)\n    \n\n    return df\n    \n    # =transform_datatypes(df)\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "/home/src/Property-Analysis-Dashboard/transformers/project_transform.py", "language": "python", "type": "transformer", "uuid": "project_transform"}, "/home/src/Property-Analysis-Dashboard/data_exporters/project_to_datalake.py:data_exporter:python:home/src/Property-Analysis-Dashboard/data exporters/project to datalake": {"content": "from mage_ai.settings.repo import get_repo_path\nfrom mage_ai.io.config import ConfigFileLoader\nfrom mage_ai.io.google_cloud_storage import GoogleCloudStorage\nfrom pandas import DataFrame\nfrom os import path\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_google_cloud_storage(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to a Google Cloud Storage bucket.\n    Specify your configuration settings in 'io_config.yaml'.\n\n    Docs: https://docs.mage.ai/design/data-loading#googlecloudstorage\n    \"\"\"\n    config_path = path.join(get_repo_path(), 'io_config.yaml')\n    config_profile = 'default'\n\n    bucket_name = 'property-analysis-dashboard'\n    object_key = 'data-report.csv'\n\n    GoogleCloudStorage.with_config(ConfigFileLoader(config_path, config_profile)).export(\n        df,\n        bucket_name,\n        object_key,\n    )\n    return df\n", "file_path": "/home/src/Property-Analysis-Dashboard/data_exporters/project_to_datalake.py", "language": "python", "type": "data_exporter", "uuid": "project_to_datalake"}}, "custom_block_template": {}, "mage_template": {"data_loaders/deltalake/s3.py:data_loader:python:Amazon S3:Load a Delta Table from Amazon S3.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_loaders/deltalake/s3.py"}, "data_loaders/deltalake/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Load a Delta Table from Azure Blob Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/deltalake/azure_blob_storage.py"}, "data_loaders/deltalake/gcs.py:data_loader:python:Google Cloud Storage:Load a Delta Table from Google Cloud Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/deltalake/gcs.py"}, "data_loaders/mongodb.py:data_loader:python:MongoDB:Load data from MongoDB.:Databases (NoSQL)": {"block_type": "data_loader", "description": "Load data from MongoDB.", "groups": ["Databases (NoSQL)"], "language": "python", "name": "MongoDB", "path": "data_loaders/mongodb.py"}, "data_loaders/mssql.py:data_loader:python:MSSQL:Load data from MSSQL.:Databases": {"block_type": "data_loader", "description": "Load data from MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_loaders/mssql.py"}, "data_exporters/deltalake/s3.py:data_exporter:python:Amazon S3:Export data to a Delta Table in Amazon S3.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_exporters/deltalake/s3.py"}, "data_exporters/deltalake/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Export data to a Delta Table in Azure Blob Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/deltalake/azure_blob_storage.py"}, "data_exporters/deltalake/gcs.py:data_exporter:python:Google Cloud Storage:Export data to a Delta Table in Google Cloud Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/deltalake/gcs.py"}, "data_exporters/mongodb.py:data_exporter:python:MongoDB:Export data to MongoDB.": {"block_type": "data_exporter", "description": "Export data to MongoDB.", "language": "python", "name": "MongoDB", "path": "data_exporters/mongodb.py"}, "data_exporters/mssql.py:data_exporter:python:MSSQL:Export data to MSSQL.:Databases": {"block_type": "data_exporter", "description": "Export data to MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_exporters/mssql.py"}, "data_loaders/orchestration/triggers/default.jinja:data_loader:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_loader", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_loaders/orchestration/triggers/default.jinja"}, "data_exporters/orchestration/triggers/default.jinja:data_exporter:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_exporter", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_exporters/orchestration/triggers/default.jinja"}, "callbacks/base.jinja:callback:python:Base template:Base template with empty functions.": {"block_type": "callback", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "callbacks/base.jinja"}, "callbacks/orchestration/triggers/default.jinja:callback:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "callback", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "callbacks/orchestration/triggers/default.jinja"}, "conditionals/base.jinja:conditional:python:Base template:Base template with empty functions.": {"block_type": "conditional", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "conditionals/base.jinja"}, "data_loaders/default.jinja:data_loader:python:Base template (generic)": {"block_type": "data_loader", "language": "python", "name": "Base template (generic)", "path": "data_loaders/default.jinja"}, "data_loaders/s3.py:data_loader:python:Amazon S3:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_loaders/s3.py"}, "data_loaders/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/azure_blob_storage.py"}, "data_loaders/google_cloud_storage.py:data_loader:python:Google Cloud Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/google_cloud_storage.py"}, "data_loaders/redshift.py:data_loader:python:Amazon Redshift:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_loaders/redshift.py"}, "data_loaders/bigquery.py:data_loader:python:Google BigQuery:Load data from Google BigQuery.:Data warehouses": {"block_type": "data_loader", "description": "Load data from Google BigQuery.", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_loaders/bigquery.py"}, "data_loaders/snowflake.py:data_loader:python:Snowflake:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_loaders/snowflake.py"}, "data_loaders/algolia.py:data_loader:python:Algolia:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_loaders/algolia.py"}, "data_loaders/chroma.py:data_loader:python:Chroma:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_loaders/chroma.py"}, "data_loaders/duckdb.py:data_loader:python:DuckDB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_loaders/duckdb.py"}, "data_loaders/mysql.py:data_loader:python:MySQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_loaders/mysql.py"}, "data_loaders/oracledb.py:data_loader:python:Oracle DB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Oracle DB", "path": "data_loaders/oracledb.py"}, "data_loaders/postgres.py:data_loader:python:PostgreSQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_loaders/postgres.py"}, "data_loaders/qdrant.py:data_loader:python:Qdrant:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_loaders/qdrant.py"}, "data_loaders/weaviate.py:data_loader:python:Weaviate:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_loaders/weaviate.py"}, "data_loaders/api.py:data_loader:python:API:Fetch data from an API request.": {"block_type": "data_loader", "description": "Fetch data from an API request.", "language": "python", "name": "API", "path": "data_loaders/api.py"}, "data_loaders/file.py:data_loader:python:Local file:Load data from a file on your machine.": {"block_type": "data_loader", "description": "Load data from a file on your machine.", "language": "python", "name": "Local file", "path": "data_loaders/file.py"}, "data_loaders/google_sheets.py:data_loader:python:Google Sheets:Load data from a worksheet in Google Sheets.": {"block_type": "data_loader", "description": "Load data from a worksheet in Google Sheets.", "language": "python", "name": "Google Sheets", "path": "data_loaders/google_sheets.py"}, "data_loaders/druid.py:data_loader:python:Druid": {"block_type": "data_loader", "language": "python", "name": "Druid", "path": "data_loaders/druid.py"}, "transformers/default.jinja:transformer:python:Base template (generic)": {"block_type": "transformer", "language": "python", "name": "Base template (generic)", "path": "transformers/default.jinja"}, "transformers/data_warehouse_transformer.jinja:transformer:python:Amazon Redshift:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "redshift", "data_source_handler": "Redshift"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Google BigQuery:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "", "data_source": "bigquery", "data_source_handler": "BigQuery"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Snowflake:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "snowflake", "data_source_handler": "Snowflake"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:PostgreSQL:Databases": {"block_type": "transformer", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "postgres", "data_source_handler": "Postgres"}}, "transformers/transformer_actions/row/drop_duplicate.py:transformer:python:Drop duplicate rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Drop duplicate rows", "path": "transformers/transformer_actions/row/drop_duplicate.py"}, "transformers/transformer_actions/row/filter.py:transformer:python:Filter rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Filter rows", "path": "transformers/transformer_actions/row/filter.py"}, "transformers/transformer_actions/row/remove.py:transformer:python:Remove rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Remove rows", "path": "transformers/transformer_actions/row/remove.py"}, "transformers/transformer_actions/row/sort.py:transformer:python:Sort rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Sort rows", "path": "transformers/transformer_actions/row/sort.py"}, "transformers/transformer_actions/column/average.py:transformer:python:Average value of column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Average value of column", "path": "transformers/transformer_actions/column/average.py"}, "transformers/transformer_actions/column/count_distinct.py:transformer:python:Count unique values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Count unique values in column", "path": "transformers/transformer_actions/column/count_distinct.py"}, "transformers/transformer_actions/column/first.py:transformer:python:First value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "First value in column", "path": "transformers/transformer_actions/column/first.py"}, "transformers/transformer_actions/column/last.py:transformer:python:Last value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Last value in column", "path": "transformers/transformer_actions/column/last.py"}, "transformers/transformer_actions/column/max.py:transformer:python:Maximum value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Maximum value in column", "path": "transformers/transformer_actions/column/max.py"}, "transformers/transformer_actions/column/median.py:transformer:python:Median value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Median value in column", "path": "transformers/transformer_actions/column/median.py"}, "transformers/transformer_actions/column/min.py:transformer:python:Min value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Min value in column", "path": "transformers/transformer_actions/column/min.py"}, "transformers/transformer_actions/column/sum.py:transformer:python:Sum of all values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Sum of all values in column", "path": "transformers/transformer_actions/column/sum.py"}, "transformers/transformer_actions/column/count.py:transformer:python:Total count of values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Total count of values in column", "path": "transformers/transformer_actions/column/count.py"}, "transformers/transformer_actions/column/clean_column_name.py:transformer:python:Clean column name:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Clean column name", "path": "transformers/transformer_actions/column/clean_column_name.py"}, "transformers/transformer_actions/column/fix_syntax_errors.py:transformer:python:Fix syntax errors:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Fix syntax errors", "path": "transformers/transformer_actions/column/fix_syntax_errors.py"}, "transformers/transformer_actions/column/reformat.py:transformer:python:Reformat values in column:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Reformat values in column", "path": "transformers/transformer_actions/column/reformat.py"}, "transformers/transformer_actions/column/select.py:transformer:python:Keep column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Keep column(s)", "path": "transformers/transformer_actions/column/select.py"}, "transformers/transformer_actions/column/remove.py:transformer:python:Remove column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Remove column(s)", "path": "transformers/transformer_actions/column/remove.py"}, "transformers/transformer_actions/column/shift_down.py:transformer:python:Shift row values down:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values down", "path": "transformers/transformer_actions/column/shift_down.py"}, "transformers/transformer_actions/column/shift_up.py:transformer:python:Shift row values up:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values up", "path": "transformers/transformer_actions/column/shift_up.py"}, "transformers/transformer_actions/column/normalize.py:transformer:python:Normalize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Normalize data", "path": "transformers/transformer_actions/column/normalize.py"}, "transformers/transformer_actions/column/standardize.py:transformer:python:Standardize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Standardize data", "path": "transformers/transformer_actions/column/standardize.py"}, "transformers/transformer_actions/column/impute.py:transformer:python:Fill in missing values:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Fill in missing values", "path": "transformers/transformer_actions/column/impute.py"}, "transformers/transformer_actions/column/remove_outliers.py:transformer:python:Remove outliers:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Remove outliers", "path": "transformers/transformer_actions/column/remove_outliers.py"}, "transformers/transformer_actions/column/diff.py:transformer:python:Calculate difference between values:Column actions:Feature extraction": {"block_type": "transformer", "groups": ["Column actions", "Feature extraction"], "language": "python", "name": "Calculate difference between values", "path": "transformers/transformer_actions/column/diff.py"}, "data_exporters/default.jinja:data_exporter:python:Base template (generic)": {"block_type": "data_exporter", "language": "python", "name": "Base template (generic)", "path": "data_exporters/default.jinja"}, "data_exporters/file.py:data_exporter:python:Local file": {"block_type": "data_exporter", "language": "python", "name": "Local file", "path": "data_exporters/file.py"}, "data_exporters/google_sheets.py:data_exporter:python:Google Sheets": {"block_type": "data_exporter", "language": "python", "name": "Google Sheets", "path": "data_exporters/google_sheets.py"}, "data_exporters/s3.py:data_exporter:python:Amazon S3:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_exporters/s3.py"}, "data_exporters/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/azure_blob_storage.py"}, "data_exporters/google_cloud_storage.py:data_exporter:python:Google Cloud Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/google_cloud_storage.py"}, "data_exporters/redshift.py:data_exporter:python:Amazon Redshift:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_exporters/redshift.py"}, "data_exporters/bigquery.py:data_exporter:python:Google BigQuery:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_exporters/bigquery.py"}, "data_exporters/snowflake.py:data_exporter:python:Snowflake:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_exporters/snowflake.py"}, "data_exporters/algolia.py:data_exporter:python:Algolia:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_exporters/algolia.py"}, "data_exporters/chroma.py:data_exporter:python:Chroma:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_exporters/chroma.py"}, "data_exporters/duckdb.py:data_exporter:python:DuckDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_exporters/duckdb.py"}, "data_exporters/mysql.py:data_exporter:python:MySQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_exporters/mysql.py"}, "data_exporters/oracledb.py:data_exporter:python:OracleDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "OracleDB", "path": "data_exporters/oracledb.py"}, "data_exporters/postgres.py:data_exporter:python:PostgreSQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_exporters/postgres.py"}, "data_exporters/qdrant.py:data_exporter:python:Qdrant:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_exporters/qdrant.py"}, "data_exporters/weaviate.py:data_exporter:python:Weaviate:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_exporters/weaviate.py"}, "sensors/default.py:sensor:python:Base template (generic)": {"block_type": "sensor", "language": "python", "name": "Base template (generic)", "path": "sensors/default.py"}, "sensors/s3.py:sensor:python:Amazon S3:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "sensors/s3.py"}, "sensors/google_cloud_storage.py:sensor:python:Google Cloud Storage:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "sensors/google_cloud_storage.py"}, "sensors/redshift.py:sensor:python:Amazon Redshift:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "sensors/redshift.py"}, "sensors/bigquery.py:sensor:python:Google BigQuery:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "sensors/bigquery.py"}, "sensors/snowflake.py:sensor:python:Snowflake:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "sensors/snowflake.py"}, "sensors/mysql.py:sensor:python:MySQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "sensors/mysql.py"}, "sensors/postgres.py:sensor:python:PostgreSQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "sensors/postgres.py"}}}